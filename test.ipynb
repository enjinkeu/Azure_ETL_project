{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, ContainerClient, BlobClient\n",
    "import os\n",
    "from tika import parser\n",
    "import pdfplumber\n",
    "import io\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "def get_secret(keyvault_name =\"chatkeys\", secret_name = \"openaiKey\"):\n",
    "    \"\"\"Get secret from Azure Key Vault\"\"\"\n",
    "    credential = DefaultAzureCredential()\n",
    "    secret_client = SecretClient(vault_url=f\"https://{keyvault_name}.vault.azure.net\", credential=credential)\n",
    "    secret = secret_client.get_secret(secret_name)\n",
    "    return secret.value\n",
    "  \n",
    "def get_cosmosdb_keys(resourceGroup,cosmosdb_name):\n",
    "    \"\"\" get cosmos db keys from azure\"\"\"\n",
    "    #create environment variables  \n",
    "    cosmosDbEndpoint_url = os.popen(f\"az cosmosdb show --resource-group {resourceGroup}  --name {cosmosdb_name} --query 'writeLocations[].documentEndpoint' -o tsv\").read().strip()\n",
    "    cosmos_account_key =   os.popen(f\"az cosmosdb keys  list --name {cosmosdb_name} --resource-group {resourceGroup} | jq -r '.primaryMasterKey'\").read().strip()    \n",
    "    database_name =        os.popen(f\"az cosmosdb database list --name {cosmosdb_name} --resource-group {resourceGroup} | jq -r '.[0].id'\").read().strip()\n",
    "    collection_name =       os.popen(f\"az cosmosdb collection list --name {cosmosdb_name} --db-name {database_name} --resource-group {resourceGroup} | jq -r '.[0].id'\").read().strip()\n",
    "    masterkey =            os.popen(f\" az cosmosdb list-keys --name {cosmosdb_name} --resource-group {resourceGroup} --query primaryMasterKey\").read().strip()\n",
    "    connection_string =    os.popen(f\"az cosmosdb keys list --type connection-strings --resource-group {resourceGroup}\\\n",
    "                              --name {cosmosdb_name} | jq '.connectionStrings[0].connectionString' \").read().strip().replace('\"','')\n",
    "    \n",
    "    return {\n",
    "        \n",
    "        \"cosmosDbEndpoint_url\" : cosmosDbEndpoint_url,\n",
    "        \"masterkey\" : masterkey,\n",
    "        \"database_name\" : database_name,\n",
    "        \"collection_name\" : collection_name,\n",
    "        \"connection_string\" : connection_string\n",
    "    }\n",
    "\n",
    "def get_cosmosdb_client():\n",
    "    \"\"\"get cosmos db client\"\"\"\n",
    "    cosmosdb_acc = get_env_vars()['cosmosdb_acc']\n",
    "    resource_group_name = get_env_vars()['resource_group_name']\n",
    "    cosmosdb_keys = get_cosmosdb_keys(resourceGroup=resource_group_name,cosmosdb_name=cosmosdb_acc)\n",
    "    cosmosdb_client = CosmosClient(cosmosdb_keys['cosmosDbEndpoint_url'], cosmosdb_keys['masterkey'])\n",
    "    return cosmosdb_client\n",
    "\n",
    "def get_env_vars():\n",
    "    env_dict = {\n",
    "        \"resource_group_name\": os.environ.get('resource_group_name'),\n",
    "        \"storage_account_name\": os.environ.get('storage_account_name'),\n",
    "        \"container_name\": os.environ.get('container_name'),\n",
    "        \"cosmosdb_acc\": os.environ.get('cosmosdb_acc'),\n",
    "        \"database_name\": os.environ.get('database_name'),\n",
    "        \"collection_name\": os.environ.get('collection_name'),\n",
    "        \"OPENAI_API_KEY\": os.environ.get('OPENAI_API_KEY'),\n",
    "    }\n",
    "    for k, v in env_dict.items():\n",
    "        if v is None:\n",
    "            raise Exception(f\"{k} environment variable is not set\")\n",
    "    return env_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['connections_string'] = cosmos_dict['connecting_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "def list_filepaths_in_container():\n",
    "    client = pymongo.MongoClient(os.environ['connections_string'])\n",
    "    collection_client = client.get_database(os.environ['database_name']).get_collection(os.environ['collection_name'])\n",
    "    list = [item['Filepath'] for item in collection_client.find()]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosmosdb_keys(resourceGroup,cosmosdb_name):\n",
    "    \"\"\" get cosmos db keys from azure\"\"\"\n",
    "    #create environment variables  \n",
    "    cosmosDbEndpoint_url = os.popen(f\"az cosmosdb show --resource-group {resourceGroup}  --name {cosmosdb_name} --query 'writeLocations[].documentEndpoint' -o tsv\").read().strip()\n",
    "    cosmos_account_key =   os.popen(f\"az cosmosdb keys  list --name {cosmosdb_name} --resource-group {resourceGroup} | jq -r '.primaryMasterKey'\").read().strip()    \n",
    "    database_name =        os.popen(f\"az cosmosdb database list --name {cosmosdb_name} --resource-group {resourceGroup} | jq -r '.[0].id'\").read().strip()\n",
    "    collection_name =       os.popen(f\"az cosmosdb collection list --name {cosmosdb_name} --db-name {database_name} --resource-group {resourceGroup} | jq -r '.[0].id'\").read().strip()\n",
    "    masterkey =            os.popen(f\" az cosmosdb list-keys --name {cosmosdb_name} --resource-group {resourceGroup} --query primaryMasterKey\").read().strip()\n",
    "    connection_string =    os.popen(f\"az cosmosdb keys list --type connection-strings --resource-group {resourceGroup}\\\n",
    "                              --name {cosmosdb_name} | jq '.connectionStrings[0].connectionString' \").read().strip().replace('\"','')\n",
    "    \n",
    "    return {\n",
    "        \n",
    "        \"cosmosDbEndpoint_url\" : cosmosDbEndpoint_url,\n",
    "        \"masterkey\" : masterkey,\n",
    "        \"database_name\" : database_name,\n",
    "        \"collection_name\" : collection_name,\n",
    "        \"connection_string\" : connection_string\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cosmosdb_keys(resourceGroup = \"chatgptGp\",cosmosdb_name=\"chatgptdb-acn\")['connection_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosmosdb_keys():\n",
    "    \"\"\" get cosmos db keys from azure\"\"\"\n",
    "    #create environment variables  \n",
    "    resourceGroup = os.environ['resource_group_name']\n",
    "    cosmosdb_name = os.environ['cosmosdb_acc']\n",
    "\n",
    "    cosmosDbEndpoint_url = os.popen(f\"az cosmosdb show --resource-group {resourceGroup}  --name {cosmosdb_name} --query 'writeLocations[].documentEndpoint' -o tsv\").read().strip()\n",
    "    cosmos_account_key =   os.popen(f\"az cosmosdb keys  list --name {cosmosdb_name} --resource-group {resourceGroup} | jq -r '.primaryMasterKey'\").read().strip()    \n",
    "    database_name =        os.popen(f\"az cosmosdb database list --name {cosmosdb_name} --resource-group {resourceGroup} | jq -r '.[0].id'\").read().strip()\n",
    "    collection_name =       os.popen(f\"az cosmosdb collection list --name {cosmosdb_name} --db-name {database_name} --resource-group {resourceGroup} | jq -r '.[0].id'\").read().strip()\n",
    "    masterkey =            os.popen(f\" az cosmosdb list-keys --name {cosmosdb_name} --resource-group {resourceGroup} --query primaryMasterKey\").read().strip()\n",
    "    connection_string =    os.popen(f\"az cosmosdb keys list --type connection-strings --resource-group {resourceGroup}\\\n",
    "                            --name {cosmosdb_name} | jq '.connectionStrings[0].connectionString' \").read().strip().replace('\"','')\n",
    "    \n",
    "    return {\n",
    "            \n",
    "            \"cosmosDbEndpoint_url\" : cosmosDbEndpoint_url,\n",
    "            \"masterkey\" : masterkey,\n",
    "            \"database_name\" : database_name,\n",
    "            \"collection_name\" : collection_name,\n",
    "            \"connection_string\" : connection_string\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = get_secret(\"chatKeys\", \"openaiKey\")   \n",
    "os.environ['storage_account_name'] = 'chatgptv2stn'\n",
    "os.environ['container_name'] = 'chatgpt-ctn'\n",
    "os.environ['resource_group_name'] ='chatgptGp'\n",
    "os.environ['cosmosdb_acc'] ='chatgptdb-acn'\n",
    "os.environ['database_name']='chatgptdb-dbn'\n",
    "os.environ['collection_name']='chatgptdb-cln' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting filepaths from cosmosdb\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "#                                                #   \n",
    "# this file will store all the utility functions #\n",
    "#                                                #\n",
    "#################################################\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import hashlib\n",
    "import datetime\n",
    "from time import time, sleep\n",
    "from typing import List\n",
    "\n",
    "import openai\n",
    "import pinecone\n",
    "import pdfplumber\n",
    "import tiktoken\n",
    "import pymongo\n",
    "from tika import parser\n",
    "from unidecode import unidecode\n",
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient, BlobClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.cosmos import CosmosClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import *\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "def cli_signIn():\n",
    "    \"\"\"function to login to azure cli if not already logged in\"\"\"\n",
    "    os.system(\"az account list --output tsv | grep True -q || az login\")\n",
    "\n",
    "######################    SECRETS       ###############################\n",
    "\n",
    "def get_secret(keyvault_name =\"chatkeys\", secret_name = \"openaiKey\"):\n",
    "    \"\"\"Get secret from Azure Key Vault\"\"\"\n",
    "    credential = DefaultAzureCredential()\n",
    "    secret_client = SecretClient(vault_url=f\"https://{keyvault_name}.vault.azure.net\", credential=credential)\n",
    "    secret = secret_client.get_secret(secret_name)\n",
    "    return secret.value\n",
    "\n",
    "def get_pinecone_keys():\n",
    "    \"\"\" get pinecone keys from azure\"\"\"\n",
    "    pinecone_api_key = get_secret(keyvault_name =\"chatkeys\", secret_name = \"pinecone\")\n",
    "    pinecone_env = get_secret(keyvault_name =\"chatkeys\", secret_name = \"pineconeEnv\")\n",
    "    pinecone_index = get_secret(keyvault_name=\"chatKeys\", secret_name=\"pineconeIdx\")\n",
    "\n",
    "    return {\n",
    "        \"pinecone.apiKey\": pinecone_api_key,\n",
    "        \"pinecone.environment\": pinecone_env,\n",
    "        \"pinecone.indexName\": pinecone_index,\n",
    "        \"pinecone.projectName\": \"chatgpt3\"\n",
    "        \n",
    "    }\n",
    "        \n",
    "def get_cosmosdb_keys():\n",
    "    \"\"\" get cosmos db keys from azure\"\"\"\n",
    "    #create environment variables  \n",
    "    \n",
    "    resourceGroup = get_env_vars()['resource_group_name']\n",
    "    cosmosdb_name = get_env_vars()['cosmosdb_acc']\n",
    "\n",
    "    cosmosDbEndpoint_url = os.popen(f\"az cosmosdb show --resource-group {resourceGroup}  --name {cosmosdb_name} --query 'writeLocations[].documentEndpoint' -o tsv\").read().strip()\n",
    "    cosmos_account_key =   os.popen(f\"az cosmosdb keys  list --name {cosmosdb_name} --resource-group {resourceGroup} | jq -r '.primaryMasterKey'\").read().strip()    \n",
    "    database_name =        os.popen(f\"az cosmosdb database list --name {cosmosdb_name} --resource-group {resourceGroup} | jq -r '.[0].id'\").read().strip()\n",
    "    collection_name =       os.popen(f\"az cosmosdb collection list --name {cosmosdb_name} --db-name {database_name} --resource-group {resourceGroup} | jq -r '.[0].id'\").read().strip()\n",
    "    masterkey =            os.popen(f\" az cosmosdb list-keys --name {cosmosdb_name} --resource-group {resourceGroup} --query primaryMasterKey\").read().strip()\n",
    "    connection_string =    os.popen(f\"az cosmosdb keys list --type connection-strings --resource-group {resourceGroup}\\\n",
    "                            --name {cosmosdb_name} | jq '.connectionStrings[0].connectionString' \").read().strip().replace('\"','')\n",
    "    \n",
    "    return {\n",
    "            \n",
    "            \"cosmosDbEndpoint_url\" : cosmosDbEndpoint_url,\n",
    "            \"masterkey\" : masterkey,\n",
    "            \"database_name\" : database_name,\n",
    "            \"collection_name\" : collection_name,\n",
    "            \"connection_string\" : connection_string\n",
    "        }\n",
    "\n",
    "def list_filepaths_in_cosmosdb_container():\n",
    "    print(\"getting filepaths from cosmosdb\")   \n",
    "    \"\"\" get cosmos db keys from azure\"\"\"\n",
    "    resource_group_name = get_env_vars()['resource_group_name']\n",
    "    cosmosdb_acc = get_env_vars()['cosmosdb_acc']\n",
    "    database_name = get_env_vars()['database_name']\n",
    "    collection_name = get_env_vars()['collection_name'] \n",
    "    client = pymongo.MongoClient(os.environ['connection_string'])\n",
    "    connecting_string = os.popen(f\"az cosmosdb keys list --type connection-strings --resource-group {resource_group_name}\\\n",
    "                              --name {cosmosdb_acc} | jq .connectionStrings[0].connectionString \").read().strip().replace('\"','')\n",
    "    collection_client = client.get_database(os.environ['database_name']).get_collection(os.environ['collection_name'])\n",
    "    list = [item['Filepath'] for item in collection_client.find()]\n",
    "    return list\n",
    "\n",
    "def set_spark_liraries():\n",
    "        #packages to load in spark session\n",
    "        group_id = \"io.pinecone\"\n",
    "        artifact_id = \"spark-pinecone_2.13\"\n",
    "        version = \"0.1.1\"\n",
    "\n",
    "        pkg1 = f\"{group_id}:{artifact_id}:{version}\"\n",
    "\n",
    "        group_id = \"com.azure.cosmos.spark\"\n",
    "        artifact_id = \"azure-cosmos-spark_3-3_2-12\"\n",
    "        version = \"4.17.2\"\n",
    "\n",
    "        pkg2 = f\"{group_id}:{artifact_id}:{version}\"\n",
    "\n",
    "        return pkg1, pkg2\n",
    "\n",
    "def get_env_vars():\n",
    "    \"\"\" get environment variables from azure\"\"\"\n",
    "    \n",
    "  \n",
    "    env_dict = {\n",
    "        \"resource_group_name\": 'chatgptGp',\n",
    "        \"storage_account_name\": 'chatgptv2stn',\n",
    "        \"container_name\": 'chatgpt-ctn',\n",
    "        \"cosmosdb_acc\": 'chatgptdb-acn',\n",
    "        \"database_name\": 'chatgptdb-dbn',\n",
    "        \"collection_name\": 'chatgptdb-cln' ,\n",
    "        \"OPENAI_API_KEY\": get_secret(keyvault_name=\"chatkeys\",secret_name=\"openaiKey\"),\n",
    "        \"connection_string\": os.popen(f\"az cosmosdb keys list --type connection-strings --resource-group 'chatgptGp'\\\n",
    "                              --name chatgptdb-acn | jq .connectionStrings[0].connectionString \").read().strip().replace('\"',''),\n",
    "    }   \n",
    "    for k, v in env_dict.items():\n",
    "        if v is None:\n",
    "            raise Exception(f\"{k} environment variable is not set\")\n",
    "    return env_dict\n",
    "\n",
    "\n",
    "######################    FILE MANAGEMENT       ###############################\n",
    "\n",
    "def list_files(startpath):\n",
    "    \"\"\" list all files in a directory\"\"\"\n",
    "    list_files = []\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        for file in files:\n",
    "            #print(os.path.join(root, file))\n",
    "            list_files.append(os.path.join(root, file))\n",
    "    return [item for item in list_files if '.pdf' in item]\n",
    "\n",
    "def list_pdfblobs():\n",
    "\n",
    "    storage_account_name = get_env_vars()['storage_account_name']\n",
    "    resource_group_name = get_env_vars()['resource_group_name']\n",
    "    container_name = get_env_vars()['container_name']\n",
    "    \"\"\"list pdf blobs in blob storage\"\"\"\n",
    "    list_of_uploaded_files = [item['Filepath'] for item in list_filepaths_in_cosmosdb_container()]\n",
    "    storage_account_key = os.popen(f\"az storage account keys list -n {storage_account_name} -g {resource_group_name} --query [0].value -o tsv\").read().strip()\n",
    "    storage_connection_string = os.popen(f\"az storage account show-connection-string -g {resource_group_name} -n {storage_account_name} --query connectionString\").read().strip()  \n",
    "    container = ContainerClient.from_connection_string(conn_str=storage_connection_string, container_name=container_name)\n",
    "    blob_list = container.list_blobs()\n",
    "    #https://<your-storage-account-name>.blob.core.windows.net/<your-container-name>/<your-blob-name>\n",
    "\n",
    "    blob_list =  [item['name'] for item in blob_list if item['name'].endswith('.pdf')  if item['name'] not in list_of_uploaded_files]\n",
    "    print(blob_list)\n",
    "    \n",
    "    return blob_list\n",
    "\n",
    "def delete_cosmosdb_uploaded_files():\n",
    "    \"\"\" get cosmos db keys from azure\"\"\"\n",
    "    resource_group_name = get_env_vars()['resource_group_name']\n",
    "    cosmosdb_acc = get_env_vars()['cosmosdb_acc']\n",
    "    database_name = get_env_vars()['database_name']\n",
    "    collection_name = get_env_vars()['collection_name']\n",
    "\n",
    "    connecting_string = os.popen(f\"az cosmosdb keys list --type connection-strings --resource-group {resource_group_name}\\\n",
    "                              --name {cosmosdb_acc} | jq .connectionStrings[0].connectionString \").read().strip().replace('\"','')\n",
    "    collection_name = pymongo.MongoClient(connecting_string)[database_name][collection_name]\n",
    "    \n",
    "    return collection_name.delete_many({})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################    PDF EXTRACTION     ###############################\n",
    "\n",
    "def extract_title(pdf_path):\n",
    "    \"\"\" extract metatdata from a pdf path\"\"\"\n",
    "    lst = pdf_path.replace('..','').split('/')[1:]\n",
    "    return lst\n",
    "\n",
    "# Extract text from a PDF file\n",
    "def preprocess_text(text):\n",
    "    # Replace any non-UTF-8 characters with a space\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_container( list_of_pdf_uploaded =list_filepaths_in_cosmosdb_container()):\n",
    "    print(\"get environment variables\")\n",
    "    storage_account_name = get_env_vars()['storage_account_name']\n",
    "    container_name = get_env_vars()['container_name']\n",
    "    resource_group_name = get_env_vars()['resource_group_name'] \n",
    "    storage_connection_string = os.popen(f\"az storage account show-connection-string -g {resource_group_name} -n {storage_account_name} --query connectionString\").read().strip()\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(storage_connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    return [(item.name,tika_parser(BlobServiceClient.from_connection_string(storage_connection_string).get_blob_client(container=container_name,blob= item.name).download_blob().content_as_bytes()))\\\n",
    "                for item in \\\n",
    "                ContainerClient.from_connection_string(conn_str=storage_connection_string, container_name=container_name).list_blobs()  \\\n",
    "                if item.name not in list_of_pdf_uploaded]\n",
    "                \n",
    "\n",
    "# Extract text from a PDF file\n",
    "def load_blob_into_memory(blob_name):\n",
    "    \"\"\"load blob into memory\"\"\"\n",
    "    \n",
    "    print(\"get environment variables\")\n",
    "    storage_account_name = get_env_vars()['storage_account_name']\n",
    "    container_name = get_env_vars()['container_name']\n",
    "    resource_group_name = get_env_vars()['resource_group_name']    \n",
    "    storage_connection_string = os.popen(f\"az storage account show-connection-string -g {resource_group_name} -n {storage_account_name} --query connectionString\").read().strip()\n",
    "\n",
    "    \n",
    "    if storage_account_name is None or container_name is None or resource_group_name is None:\n",
    "        raise Exception(\"Missing environment variables\")\n",
    "    elif blob_name is None:\n",
    "        raise Exception(\"Missing blob name\")\n",
    "        return ''\n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            #connection string\n",
    "            storage_connection_string = os.popen(f\"az storage account show-connection-string -g {resource_group_name} -n {storage_account_name} --query connectionString\").read().strip()\n",
    "\n",
    "            # Create blob service client\n",
    "            blob_service_client = BlobServiceClient.from_connection_string(storage_connection_string)\n",
    "            # Get blob client\n",
    "            blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)     \n",
    "            \n",
    "            # Check if blob exists\n",
    "            if blob_client.exists():\n",
    "                # Download blob data\n",
    "                blob_data = blob_client.download_blob().content_as_bytes()    \n",
    "                print(f\"Successfully downloaded blob: {blob_client.blob_name}\")\n",
    "                return blob_data\n",
    "            else:\n",
    "                print(f\"Blob {blob_client.blob_name} does not exist\")   \n",
    "               \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading blob: {e}\")\n",
    "\n",
    "# Extract text from a PDF file\n",
    "def tika_parser(blob_data):\n",
    "    try:\n",
    "        with io.BytesIO(blob_data) as pdf_file:\n",
    "            # Try to extract text using Tika parser\n",
    "            try:\n",
    "                parsed_pdf = parser.from_buffer(pdf_file)\n",
    "                text = parsed_pdf['content']\n",
    "                print(f\"Successfully extracted {len(text)} characters from PDF using Tika\")\n",
    "                return text\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # If Tika fails, try to extract text using pdfplumber\n",
    "            try:\n",
    "                with pdfplumber.load(pdf_file) as pdf:\n",
    "                    pages = pdf.pages\n",
    "                    text = \"\\n\".join([page.extract_text() for page in pages])\n",
    "                    print(f\"Successfully extracted {len(text)} characters from PDF using pdfplumber\")\n",
    "                    return text\n",
    "            except:\n",
    "                \n",
    "                pass\n",
    "\n",
    "            # If both Tika and pdfplumber fail, return None\n",
    "            print(\"Failed to extract text from PDF using Tika or pdfplumber\")\n",
    "            return None\n",
    "    except:\n",
    "        print(\"Error reading PDF file from memory\")\n",
    "        return ''\n",
    "\n",
    "\n",
    "\n",
    "def chatgpt3 (userinput, temperature=0.7, frequency_penalty=0, presence_penalty=0):\n",
    "    \"\"\" chat with gpt-3.5-turbo, the much cheaper version of gpt-3\"\"\"\n",
    "    \n",
    "    suffix = \"\\n\\nTl;dr\"\n",
    "    prompt = userinput+suffix\n",
    "    assistant_prompt =\"\"\n",
    "    message = [\n",
    "        {\"role\": \"user\", \"content\": prompt },        \n",
    "        {\"role\": \"system\", \"content\": \"you are a helpful distinguished scholarly assistant that uses efficient \\\n",
    "         communication to help finish the task of concisely summarizing an article by summarizing the most pertinent essence of the text as part of a paragraph. \\\n",
    "         use the fewest words as possible in english\"}\n",
    "         ]\n",
    "    openai.api_key = get_env_vars()['OPENAI_API_KEY']\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=temperature,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        messages=message\n",
    "    )\n",
    "    text = response['choices'][0]['message']['content']\n",
    "    return text\n",
    "\n",
    "def cheaper_summarizer(text, title,temperature=0.7, frequency_penalty=0, presence_penalty=0,api_key=None):\n",
    "    \"\"\" chat with gpt-3.5-turbo, the much cheaper version of gpt-3\"\"\"        \n",
    "    \n",
    "    if text is None:\n",
    "        print(f\"there is no text to summarize - Skipping {title}\")\n",
    "        return ''\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"Summarizing {title} for {len(text)} characters\")\n",
    "            #split text into chunks\n",
    "            chunks = split_text(text)\n",
    "            max_retry = 3\n",
    "            retry = 0\n",
    "            while retry < max_retry:\n",
    "                try:\n",
    "                    summaries = ' \\n'.join([chatgpt3(chunk, temperature=temperature, frequency_penalty=frequency_penalty, presence_penalty=presence_penalty) for chunk in chunks])\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception: {e} - Retrying {title}\") \n",
    "                    retry += 1\n",
    "                    sleep(5)\n",
    "                    continue                \n",
    "            return summaries\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e} - Skipping {title}\")\n",
    "            return ''\n",
    "   \n",
    "                            \n",
    "    \n",
    "\n",
    "     \n",
    "def create_id(folder, typeofDoc, subject, author, title):\n",
    "    \"\"\" create id field for cosmos db \"\"\"\n",
    "    # create a string to hash\n",
    "    my_string = f\"{folder}{typeofDoc}{subject}{author}{title}\"\n",
    "    # create a hash object using the SHA-256 algorithm\n",
    "    hash_object = hashlib.sha256()\n",
    "    # update the hash object with the string to be hashed\n",
    "    hash_object.update(my_string.encode())\n",
    "    # get the hexadecimal representation of the hash\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    return hex_dig\n",
    "\n",
    "######################    VECTOR DATABASE DATA LOADING     ###############################\n",
    "def split_text(text: str):\n",
    "    \"\"\" split text into chunks\"\"\"\n",
    "    text_splitter = CharacterTextSplitter()\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    " \n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    \"\"\" get embedding from openai\"\"\"\n",
    "    openai.api_key = get_env_vars()['OPENAI_API_KEY']\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "def get_pincone_pdfdata( text,metadata):    \n",
    "    \"\"\" get pinecone pdf data\"\"\"\n",
    "    #create list of vectors\n",
    "    chunks = split_text(text)   \n",
    "    \n",
    "    #create list of pinecone documents\n",
    "    pinecone_docs = [{\"id\": hashlib.sha256(item.encode()).hexdigest(),\n",
    "                        \"values\": [get_embedding(item )],\n",
    "                        \"metadata\": metadata\n",
    "                         } for item in chunks]  \n",
    "    return pinecone_docs\n",
    "\n",
    "\n",
    "######################    UPLOAD DATA     ###############################\n",
    "\n",
    "def upsert_pinecone_data(vector):\n",
    "    \"\"\" upsert pinecone data\"\"\"\n",
    "    \"\"\" upsert pinecone index with pdf data\"\"\"\n",
    "    pinecone.apiKey = get_pinecone_keys()['pinecone.apiKey']\n",
    "    pinecone.environment = get_pinecone_keys()['pinecone.environment']\n",
    "    pinecone.indexName = get_pinecone_keys()['pinecone.indexName']\n",
    "    pinecone.projectName = get_pinecone_keys()['pinecone.projectName']\n",
    "    \n",
    "    #initialize pinecone\n",
    "    pinecone.init(api_key=pinecone.apiKey, env=pinecone.environment)\n",
    "    \n",
    "    index = pinecone.Index(pinecone.indexName)\n",
    "    return index.upsert(vector , namespace=pinecone.projectName)\n",
    "\n",
    "def write_to_cosmosdb(items):\n",
    "    \n",
    "    resource_group_name =  os.environ.get('resource_group_name')\n",
    "    cosmosdb_acc =         os.environ.get('cosmosdb_acc')\n",
    "    database_name =        os.environ.get('database_name')\n",
    "    collection_name =      os.environ.get('collection_name')\n",
    "    connecting_string = os.popen(f\"az cosmosdb keys list --type connection-strings --resource-group {resource_group_name}\\\n",
    "                              --name {cosmosdb_acc} | jq '.connectionStrings[0].connectionString' \").read().strip().replace('\"','')\n",
    "    \n",
    "    mongo_client = MongoClient(connecting_string)\n",
    "    collection = mongo_client[database_name][collection_name]\n",
    "\n",
    "    for item in items:\n",
    "        print(item['summary'])\n",
    "        collection.update_one({\"id\": item[\"id\"]}, {\"$set\": item}, upsert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting filepaths from cosmosdb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/src/AcademicJournal/anthropology/beemster/Les Tikar de Bankim.pdf',\n",
       " '/src/AcademicJournal/history/Ndobegang_Mbapndah/COLONIAL BACKGROUND TO THE ECONOMIC EMPOWERMENT AND POLITICAL MOBILIZATION.pdf',\n",
       " \"/src/AcademicJournal/anthropology/Annaud/De l'intestin aux testicules Substances, humeurs et alliance tikar - Cameroun central.pdf\",\n",
       " '/src/AcademicJournal/anthropology/Price/Descent, Clans and Territorial Organization in the Tikar Chiefdom of Ngambe, Cameroon.pdf',\n",
       " '/src/OpED/philosophy/nganang/LE COMPLEXE DE SENGHOR.pdf',\n",
       " '/src/AcademicJournal/anthropology/Price/WHO ARE THE TIKAR NOW.pdf',\n",
       " '/src/AcademicJournal/anthropology/Jeffreys/Who are the Tikar.pdf',\n",
       " '/src/AcademicJournal/anthropology/chilver_kaberry/FROM TRIBUTE TO TAX IN A TIKAR CHIEFDOM.pdf',\n",
       " '/src/AcademicJournal/anthropology/hagege/Esquisse linguistique du Tikar, Cameroun (Claude HagÃ¨ge).pdf',\n",
       " '/src/AcademicJournal/geopolitics/Nganang/The Amba Uprising Beyond Frances.pdf',\n",
       " '/src/AcademicJournal/anthropology/Tchindakenfo/le probleme anglophone au cameroun - La reponse par le processus participatif au developpement territorial.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_filepaths_in_cosmosdb_container()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
